# Azure-Centric AI Service Layer

This module provides a unified interface for AI operations backed by Azure OpenAI services. Optimized for enterprise-grade AI functionality with robust error handling and retry mechanisms.

## Features

- ‚ö° **Azure OpenAI Integration**: Enterprise-grade AI powered by Azure OpenAI
- üõ°Ô∏è **Enhanced Service Layer**: Multi-deployment support with automatic fallback
- üéØ **Consistent Interface**: Unified API for all AI operations
- üîÑ **Retry Logic**: Exponential backoff with Application Insights logging
- üß™ **Fully Tested**: Comprehensive unit tests with Jest mocks

## Quick Start

### Basic Usage

```typescript
import { generateCoverLetter, tailorResume, calculateRelevancy } from '@/lib/ai';

// Generate a cover letter
const coverLetterResponse = await generateCoverLetter(resumeText, jobDescription);
if (coverLetterResponse.success) {
  console.log('Cover letter:', coverLetterResponse.data);
  console.log('Generated by:', coverLetterResponse.provider);
}

// Tailor a resume
const tailoredResponse = await tailorResume(resumeText, jobDescription);
if (tailoredResponse.success) {
  console.log('Tailored resume:', tailoredResponse.data);
}

// Calculate relevancy score (0-100)
const relevancyResponse = await calculateRelevancy(resumeText, jobDescription);
if (relevancyResponse.success) {
  console.log('Relevancy score:', relevancyResponse.data); // e.g., 85
}
```

### Provider Configuration

The service uses Azure OpenAI exclusively:

```bash
# Azure OpenAI is the only supported provider
AI_PROVIDER=azure-openai
```

## Available Functions

### `generateCoverLetter(resumeText: string, jobDescription: string)`

Generates a professional cover letter tailored to the job description.

**Returns:** `AIResponse<string>`

```typescript
const response = await generateCoverLetter(
  'John Doe\nSoftware Engineer with 5 years experience...',
  'We are seeking a Senior React Developer...'
);
```

### `calculateRelevancy(resumeText: string, jobDescription: string)`

Calculates a relevancy score (0-100) between the resume and job description.

**Returns:** `AIResponse<number>`

```typescript
const response = await calculateRelevancy(resumeText, jobDescription);
// response.data will be between 0-100
```

### `tailorResume(resumeText: string, jobDescription: string)`

Optimizes a resume for ATS compatibility and job relevance.

**Returns:** `AIResponse<string>`

```typescript
const response = await tailorResume(originalResume, jobDescription);
```

### `generateQuestions(resumeInfo: ResumeInfo)`

Generates interview questions based on resume information.

**Returns:** `AIResponse<string[]>`

```typescript
const resumeInfo = {
  name: 'John Doe',
  experience: '5 years in web development',
  education: 'BS Computer Science',
  skills: 'React, Node.js, TypeScript'
};

const response = await generateQuestions(resumeInfo);
// response.data will contain up to 5 questions
```

### `getProviderInfo()`

Returns information about the current AI provider.

**Returns:** `{ name: string; isReady: boolean }`

```typescript
const info = getProviderInfo();
console.log(`Using ${info.name}, Ready: ${info.isReady}`);
```

### `switchProvider(providerName: string)`

Switches to a different AI provider at runtime.

**Returns:** `AIResponse<boolean>`

```typescript
const response = await switchProvider('azure-openai');
if (response.success) {
  console.log('Switched to Azure OpenAI');
}
```

## Response Format

All AI functions return a consistent `AIResponse<T>` format:

```typescript
interface AIResponse<T = any> {
  success: boolean;    // Whether the operation succeeded
  data?: T;           // The response data (if successful)
  error?: string;     // Error message (if failed)
  provider?: string;  // Name of the provider used
}
```

## AI Provider

### Azure OpenAI (`azure-openai`)

- **Model**: Configurable deployment models (GPT-4, GPT-3.5-turbo, etc.)
- **Configuration**: Uses Azure Key Vault for secure credential management
- **Features**: Enterprise-grade, consistent performance, advanced reasoning, secure credential handling

## Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `AI_PROVIDER` | Must be set to `azure-openai` | Yes |
| Azure Key Vault credentials | Azure tenant, client ID, client secret | Yes |

### Configuration Requirements

1. **AI_PROVIDER**: Must be set to `azure-openai`
2. **Azure Credentials**: Required for Azure Key Vault access
3. **Azure OpenAI**: Must be properly configured in Azure

## Error Handling

The service layer provides robust error handling:

```typescript
const response = await generateCoverLetter(resumeText, jobDescription);

if (!response.success) {
  console.error('Error:', response.error);
  console.log('Provider:', response.provider);
  
  // Handle specific error types
  if (response.error?.includes('quota')) {
    // Handle rate limiting
  } else if (response.error?.includes('API key')) {
    // Handle authentication issues
  }
}
```

## Architecture

```
lib/ai/
‚îú‚îÄ‚îÄ index.ts              # Main service layer
‚îú‚îÄ‚îÄ azureOpenAI.ts        # Azure OpenAI adapter
‚îú‚îÄ‚îÄ README.md            # This documentation
‚îî‚îÄ‚îÄ __tests__/
    ‚îú‚îÄ‚îÄ index.test.ts         # Service layer tests
    ‚îî‚îÄ‚îÄ azureOpenAI.test.ts   # Azure adapter tests
```

### Key Components

- **AIServiceManager**: Manages Azure OpenAI provider lifecycle
- **AIProvider Interface**: Common interface for AI operations
- **Adapter Pattern**: Wraps Azure OpenAI service with consistent interface
- **Error Handling**: Standardized error responses and retry logic

## Testing

Run the test suite:

```bash
# Run all AI service tests
npm test lib/ai/__tests__

# Run with coverage
npm run test:coverage -- lib/ai/__tests__

# Run specific test files
npm test lib/ai/__tests__/index.test.ts
npm test lib/ai/__tests__/azureOpenAI.test.ts
```

### Test Coverage

- ‚úÖ Azure OpenAI provider initialization
- ‚úÖ All AI functions with various inputs
- ‚úÖ Error handling and edge cases
- ‚úÖ Concurrent requests
- ‚úÖ Mocked external dependencies

## Migration Guide

### From Direct Azure OpenAI Usage

**Before:**
```typescript
import { azureOpenAIService } from '@/lib/services/azure-openai-service';

await azureOpenAIService.initialize();
const tailored = await azureOpenAIService.tailorResume(resume, job);
```

**After:**
```typescript
import { tailorResume } from '@/lib/ai';

const response = await tailorResume(resume, job);
const tailored = response.data; // Handles initialization automatically
```

## Performance Considerations

- **Initialization**: Providers are initialized lazily on first use
- **Caching**: Provider instances are reused across requests
- **Retry Logic**: Built-in exponential backoff for rate limiting
- **Concurrent Requests**: Safe for concurrent operations

## Contributing

When adding a new AI provider:

1. Create an adapter implementing the `AIProvider` interface
2. Register it in the `AIServiceManager` constructor
3. Add comprehensive unit tests
4. Update this documentation

### Example New Provider

```typescript
export class NewProviderAdapter implements AIProvider {
  public name = 'New Provider';
  
  async initialize(): Promise<boolean> {
    // Initialize your provider
  }
  
  isReady(): boolean {
    // Check if ready
  }
  
  // Implement all required methods...
}
```

## Troubleshooting

### Common Issues

**Provider not initializing:**
```bash
# Check environment variables
echo $AI_PROVIDER

# Check Azure credentials
echo $AZURE_TENANT_ID
echo $AZURE_CLIENT_ID

# Check logs for initialization errors
```

**API quota exceeded:**
- Check your Azure OpenAI usage and limits
- Consider implementing request queuing
- Monitor Azure OpenAI service health

**Network timeouts:**
- Built-in retry logic handles temporary failures
- Check network connectivity and firewall settings

### Debug Mode

Enable detailed logging by setting the provider environment variable:

```bash
AI_PROVIDER=azure-openai npm run dev
```

Check the console for detailed initialization and operation logs.

## License

This AI service layer is part of the PrepBettr project and follows the same licensing terms.

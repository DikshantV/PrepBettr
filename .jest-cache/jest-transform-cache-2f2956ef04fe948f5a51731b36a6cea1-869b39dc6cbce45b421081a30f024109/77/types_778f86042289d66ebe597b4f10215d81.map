{"version":3,"names":["cov_22dgb99dw9","path","hash","global","Function","gcv","coverageData","statementMap","start","line","column","end","fnMap","branchMap","s","f","b","inputSourceMap","file","mappings","names","sources","sourcesContent","version","_coverageSchema","coverage","actualCoverage"],"sources":["/Users/dikshantvashistha/PrepBettr/lib/azure-ai-foundry/voice/types.ts"],"sourcesContent":["/**\n * Azure AI Foundry Voice Integration Types\n * Comprehensive type definitions for voice-enabled interview system\n */\n\n// ===== VOICE CONFIGURATION TYPES =====\n\nexport interface VoiceSettings {\n  // Speech-to-Text Configuration\n  inputAudioFormat: 'pcm16' | 'pcm24' | 'opus';\n  inputSampleRate: number;\n  language: string;\n  \n  // Text-to-Speech Configuration  \n  outputAudioFormat: 'pcm16' | 'pcm24' | 'opus';\n  outputSampleRate: number;\n  voice: string;\n  \n  // Conversation Parameters\n  temperature: number;\n  maxTokens: number;\n  systemMessage: string;\n  \n  // Voice Activity Detection\n  turnDetection: {\n    type: 'server_vad' | 'none';\n    threshold?: number;\n    prefix_padding_ms?: number;\n    silence_duration_ms?: number;\n  };\n  \n  // Agent-specific Settings\n  personality?: 'professional' | 'friendly' | 'technical' | 'empathetic';\n  speakingPace?: 'slow' | 'normal' | 'fast';\n  responseStyle?: 'concise' | 'detailed' | 'conversational';\n}\n\nexport interface ConfigOptions extends VoiceSettings {\n  // Connection Settings\n  endpoint: string;\n  apiKey: string;\n  deploymentId: string;\n  \n  // Format Settings (legacy compatibility)\n  inputFormat: string;\n  outputFormat: string;\n  instructionMessage: string;\n}\n\n// ===== AGENT-SPECIFIC VOICE SETTINGS =====\n\nexport interface AgentVoiceConfig {\n  agentType: 'technical' | 'behavioral' | 'industry' | 'general';\n  defaultVoiceSettings: Partial<VoiceSettings>;\n  voicePersonality: {\n    systemPromptAddition: string;\n    responseCharacteristics: string[];\n  };\n  interactionStyle: {\n    questionPacing: number; // seconds between questions\n    followUpStyle: 'immediate' | 'delayed' | 'contextual';\n    errorRecovery: 'restart' | 'clarify' | 'skip';\n  };\n}\n\n// ===== REAL-TIME TRANSCRIPT TYPES =====\n\nexport interface TranscriptEntry {\n  id: string;\n  timestamp: number;\n  speaker: 'user' | 'agent';\n  text: string;\n  confidence?: number;\n  isPartial?: boolean;\n  wordTimings?: {\n    word: string;\n    startTime: number;\n    endTime: number;\n    confidence: number;\n  }[];\n}\n\nexport interface TranscriptSession {\n  sessionId: string;\n  startTime: number;\n  endTime?: number;\n  entries: TranscriptEntry[];\n  metadata: {\n    totalDuration: number;\n    wordCount: number;\n    averageConfidence: number;\n    language: string;\n  };\n}\n\n// ===== SENTIMENT DETECTION TYPES =====\n\nexport interface SentimentAnalysis {\n  score: number; // -1 to 1 (negative to positive)\n  magnitude: number; // 0 to 1 (intensity)\n  label: 'very_negative' | 'negative' | 'neutral' | 'positive' | 'very_positive';\n  confidence: number;\n  stressIndicators: {\n    hasHighStressWords: boolean;\n    stressWords: string[];\n    speechPattern: 'normal' | 'rushed' | 'hesitant' | 'unclear';\n    emotionalState: 'calm' | 'nervous' | 'excited' | 'frustrated';\n  };\n}\n\nexport interface SentimentTrend {\n  sessionId: string;\n  timeline: {\n    timestamp: number;\n    sentiment: SentimentAnalysis;\n    transcriptId: string;\n  }[];\n  summary: {\n    averageSentiment: number;\n    trendDirection: 'improving' | 'declining' | 'stable';\n    stressEvents: number;\n    recommendedInterventions: string[];\n  };\n}\n\n// ===== RECORDING AND STORAGE TYPES =====\n\nexport interface AudioChunk {\n  id: string;\n  sessionId: string;\n  timestamp: number;\n  duration: number; // in milliseconds\n  format: string;\n  sampleRate: number;\n  data: ArrayBuffer;\n  metadata: {\n    speaker: 'user' | 'agent';\n    quality: 'low' | 'medium' | 'high';\n    noiseLevel: number;\n  };\n}\n\nexport interface SessionRecording {\n  sessionId: string;\n  startTime: number;\n  endTime?: number;\n  totalDuration: number;\n  chunks: AudioChunk[];\n  storageLocation: {\n    containerName: string;\n    blobName: string;\n    url?: string;\n  };\n  processingStatus: 'uploading' | 'processing' | 'completed' | 'failed';\n  transcriptId?: string;\n}\n\n// ===== VOICE SESSION STATE TYPES =====\n\nexport interface VoiceSessionState {\n  sessionId: string;\n  status: 'initializing' | 'connected' | 'active' | 'paused' | 'ended' | 'error';\n  currentAgent: string;\n  activeTranscript: TranscriptSession;\n  sentimentAnalysis: SentimentTrend;\n  recording?: SessionRecording;\n  \n  // Real-time Metrics\n  metrics: {\n    connectionLatency: number;\n    audioLatency: number;\n    transcriptionAccuracy: number;\n    responseTime: number;\n    totalSpeakingTime: number;\n    silenceDuration: number;\n  };\n  \n  // Error Tracking\n  errors: {\n    timestamp: number;\n    type: 'connection' | 'audio' | 'transcription' | 'synthesis';\n    message: string;\n    recovered: boolean;\n  }[];\n}\n\n// ===== EVENT TYPES FOR VOICE BRIDGE =====\n\nexport interface VoiceEventTypes {\n  // Session Events\n  'session:started': { sessionId: string; agent: string };\n  'session:ended': { sessionId: string; reason: string };\n  'session:error': { sessionId: string; error: Error };\n  \n  // Transcription Events\n  'transcript:partial': { sessionId: string; text: string; confidence: number };\n  'transcript:final': { sessionId: string; entry: TranscriptEntry };\n  'transcript:error': { sessionId: string; error: string };\n  \n  // Audio Events\n  'audio:received': { sessionId: string; chunk: AudioChunk };\n  'audio:synthesis:start': { sessionId: string; text: string };\n  'audio:synthesis:complete': { sessionId: string; audioData: string };\n  'audio:playback:start': { sessionId: string };\n  'audio:playback:end': { sessionId: string };\n  \n  // Agent Events\n  'agent:handoff': { from: string; to: string; context: any };\n  'agent:response': { agent: string; text: string; audioData?: string };\n  'agent:thinking': { agent: string; isThinking: boolean };\n  \n  // Sentiment Events\n  'sentiment:analysis': { sessionId: string; sentiment: SentimentAnalysis };\n  'sentiment:stress:detected': { sessionId: string; level: 'moderate' | 'high'; suggestions: string[] };\n}\n\n// ===== UTILITY TYPES =====\n\nexport type VoiceEventHandler<T extends keyof VoiceEventTypes> = (event: VoiceEventTypes[T]) => void;\n\nexport interface VoiceCapabilities {\n  supportedLanguages: string[];\n  supportedVoices: string[];\n  supportedFormats: {\n    input: string[];\n    output: string[];\n  };\n  features: {\n    realTimeTranscription: boolean;\n    sentimentAnalysis: boolean;\n    voiceActivityDetection: boolean;\n    noiseReduction: boolean;\n    multipleAgents: boolean;\n  };\n}\n\n// ===== AZURE AI FOUNDRY SPECIFIC TYPES =====\n\nexport interface FoundryVoiceSession {\n  id: string;\n  status: 'active' | 'inactive' | 'terminated';\n  model: string;\n  modalities: ('text' | 'audio')[];\n  instructions: string;\n  voice: string;\n  inputAudioFormat: string;\n  outputAudioFormat: string;\n  turnDetection: VoiceSettings['turnDetection'];\n  temperature: number;\n  maxResponseOutputTokens: number | null;\n}\n\nexport interface FoundryVoiceMessage {\n  type: string;\n  [key: string]: any;\n}\n\nexport interface FoundryVoiceError {\n  type: string;\n  code: string;\n  message: string;\n  param?: string;\n  eventId?: string;\n}\n\n// ===== AGENT BRIDGE TYPES =====\n\nexport interface AgentBridgeConfig {\n  sessionTimeout: number;\n  maxRetries: number;\n  errorRecoveryMode: 'graceful' | 'immediate' | 'manual';\n  sentimentMonitoring: boolean;\n  recordingEnabled: boolean;\n  transcriptStorage: 'memory' | 'persistent' | 'both';\n}\n\nexport interface BridgeState {\n  currentAgent: string | null;\n  sessionActive: boolean;\n  lastActivity: number;\n  pendingHandoff: boolean;\n  errorCount: number;\n  recovery: {\n    inProgress: boolean;\n    attempts: number;\n    lastAttempt: number;\n  };\n}\n"],"mappings":";;AAAA;;;;AAAA;AAAA,SAAAA,eAAA;EAAA,IAAAC,IAAA;EAAA,IAAAC,IAAA;EAAA,IAAAC,MAAA,OAAAC,QAAA;EAAA,IAAAC,GAAA;EAAA,IAAAC,YAAA;IAAAL,IAAA;IAAAM,YAAA;MAAA;QAAAC,KAAA;UAAAC,IAAA;UAAAC,MAAA;QAAA;QAAAC,GAAA;UAAAF,IAAA;UAAAC,MAAA;QAAA;MAAA;IAAA;IAAAE,KAAA;IAAAC,SAAA;IAAAC,CAAA;MAAA;IAAA;IAAAC,CAAA;IAAAC,CAAA;IAAAC,cAAA;MAAAC,IAAA;MAAAC,QAAA;MAAAC,KAAA;MAAAC,OAAA;MAAAC,cAAA;MAAAC,OAAA;IAAA;IAAAC,eAAA;IAAAtB,IAAA;EAAA;EAAA,IAAAuB,QAAA,GAAAtB,MAAA,CAAAE,GAAA,MAAAF,MAAA,CAAAE,GAAA;EAAA,KAAAoB,QAAA,CAAAxB,IAAA,KAAAwB,QAAA,CAAAxB,IAAA,EAAAC,IAAA,KAAAA,IAAA;IAAAuB,QAAA,CAAAxB,IAAA,IAAAK,YAAA;EAAA;EAAA,IAAAoB,cAAA,GAAAD,QAAA,CAAAxB,IAAA;EAAA","ignoreList":[]}